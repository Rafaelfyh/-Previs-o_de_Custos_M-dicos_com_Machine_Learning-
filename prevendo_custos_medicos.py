# -*- coding: utf-8 -*-
"""Prevendo_custos_medicos.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U43w5Il3gYcYOIISMQeTo0YU5uZrjL3k
"""

# Importando bibliotecas
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Carregar o arquivo CSV
file_path = '/content/insurance.csv'  # Corrigido o erro de sintaxe
insurance_data = pd.read_csv(file_path)

# Visualizar as primeiras linhas dos dados
print(insurance_data.head())

# Visualizar as primeiras linhas dos dados
print(insurance_data.head())

# Estat√≠sticas descritivas
print(insurance_data.describe())

# Visualizar distribui√ß√µes das vari√°veis num√©ricas
insurance_data[['age', 'bmi', 'children', 'charges']].hist(figsize=(10, 8))
plt.tight_layout()
plt.show()

# Gr√°ficos de dispers√£o entre 'charges' e outras vari√°veis num√©ricas
sns.pairplot(insurance_data[['age', 'bmi', 'children', 'charges']], diag_kind='kde')
plt.show()

# Boxplot para verificar outliers
plt.figure(figsize=(12, 6))
sns.boxplot(data=insurance_data[['age', 'bmi', 'children', 'charges']])
plt.show()

# An√°lise de correla√ß√£o entre as vari√°veis
correlation_matrix = insurance_data[['age', 'bmi', 'children', 'charges']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.show()

"""# Pr√©-processamento dos Dados"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

# Verificar valores ausentes
print(insurance_data.isnull().sum())

# Codifica√ß√£o das vari√°veis categ√≥ricas 'sex', 'smoker' e 'region'
label_encoder = LabelEncoder()
insurance_data['sex'] = label_encoder.fit_transform(insurance_data['sex'])
insurance_data['smoker'] = label_encoder.fit_transform(insurance_data['smoker'])
insurance_data['region'] = label_encoder.fit_transform(insurance_data['region'])

# Normaliza√ß√£o das vari√°veis num√©ricas (age, bmi, children)
scaler = StandardScaler()
insurance_data[['age', 'bmi', 'children']] = scaler.fit_transform(insurance_data[['age', 'bmi', 'children']])

# Separando as vari√°veis independentes (X) e dependente (y)
X = insurance_data[['age', 'sex', 'bmi', 'children', 'smoker', 'region']]
y = insurance_data['charges']

# Divis√£o em treino e teste (80% treino, 20% teste)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Constru√ß√£o do Modelo de Regress√£o Linear"""

from sklearn.linear_model import LinearRegression

# Criar o modelo
model = LinearRegression()

# Treinamento do modelo
model.fit(X_train, y_train)

# Coeficientes do modelo
print("Coeficientes:", model.coef_)
print("Intercepto:", model.intercept_)

"""# Avalia√ß√£o do Modelo"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Predi√ß√µes no conjunto de teste
y_pred = model.predict(X_test)

# Avalia√ß√£o do modelo
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print("R¬≤:", r2)
print("RMSE:", rmse)

"""# Valida√ß√£o e Refinamento"""

from sklearn.model_selection import cross_val_score

# Valida√ß√£o cruzada
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')

print("Valida√ß√£o cruzada (MSE negativo):", cv_scores)

"""# Analise de res√≠duos

"""

import matplotlib.pyplot as plt
import seaborn as sns

# Calcular os res√≠duos
residuals = y_test - y_pred

# Plotar os res√≠duos
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Res√≠duos vs. Previs√µes')
plt.xlabel('Previs√µes')
plt.ylabel('Res√≠duos')
plt.show()

# Plotar o histograma dos res√≠duos
plt.figure(figsize=(10, 6))
sns.histplot(residuals, bins=30, kde=True)
plt.title('Distribui√ß√£o dos Res√≠duos')
plt.xlabel('Res√≠duos')
plt.ylabel('Frequ√™ncia')
plt.show()

# Verificar a m√©dia e vari√¢ncia dos res√≠duos
print("M√©dia dos res√≠duos:", residuals.mean())
print("Desvio padr√£o dos res√≠duos:", residuals.std())

import matplotlib.pyplot as plt
import seaborn as sns

# Calcular os res√≠duos
residuals = y_test - y_pred

# Plotar os res√≠duos
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.title('Res√≠duos vs. Previs√µes')
plt.xlabel('Previs√µes')
plt.ylabel('Res√≠duos')
plt.show()

# Plotar o histograma dos res√≠duos
plt.figure(figsize=(10, 6))
sns.histplot(residuals, bins=30, kde=True)
plt.title('Distribui√ß√£o dos Res√≠duos')
plt.xlabel('Res√≠duos')
plt.ylabel('Frequ√™ncia')
plt.show()

# Verificar a m√©dia e vari√¢ncia dos res√≠duos
print("M√©dia dos res√≠duos:", residuals.mean())
print("Desvio padr√£o dos res√≠duos:", residuals.std())

"""##  An√°lise do Resultado:
* A boa performance em termos de R¬≤ (78,3%) indica que, em geral, o modelo est√° acertando as previs√µes para a maior parte dos dados.

* RMSE e os resultados da valida√ß√£o cruzada mostram que o modelo ainda pode cometer erros significativos em algumas previs√µes.

* O erro relativamente alto em algumas divis√µes (valores negativos de MSE) indica que pode haver oportunidades para melhorar o modelo, talvez incluindo mais vari√°veis ou ajustando o modelo para capturar melhor as n√£o-linearidades.
"""

# Calcular a correla√ß√£o entre as vari√°veis
corr_matrix = insurance_data.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriz de Correla√ß√£o')
plt.show()

"""# Regulariza√ß√£o (Lasso e Ridge)

"""

from sklearn.linear_model import Ridge, Lasso

# Modelos de regulariza√ß√£o
ridge_model = Ridge(alpha=1.0)
lasso_model = Lasso(alpha=0.1)

# Treinando os modelos
ridge_model.fit(X_train, y_train)
lasso_model.fit(X_train, y_train)

# Avalia√ß√£o do modelo
ridge_pred = ridge_model.predict(X_test)
lasso_pred = lasso_model.predict(X_test)

# Comparando desempenho
ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_pred))
lasso_rmse = np.sqrt(mean_squared_error(y_test, lasso_pred))

print(f"Ridge RMSE: {ridge_rmse}")
print(f"Lasso RMSE: {lasso_rmse}")

"""# Testes com outros modelos"""

from sklearn.ensemble import RandomForestRegressor

# Modelo RandomForest
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Treinamento
rf_model.fit(X_train, y_train)

# Previs√µes
rf_pred = rf_model.predict(X_test)

# Avalia√ß√£o do modelo
rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))
rf_r2 = r2_score(y_test, rf_pred)

print(f"Random Forest RMSE: {rf_rmse}")
print(f"Random Forest R¬≤: {rf_r2}")

"""# Ajuste Fino e Hiperpar√¢metros"""

from sklearn.model_selection import GridSearchCV

# Definir os par√¢metros a serem ajustados
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Realizar busca de par√¢metros
grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, n_jobs=-1)
grid_search.fit(X_train, y_train)

# Melhor modelo
print("Melhores par√¢metros:", grid_search.best_params_)

# Avalia√ß√£o do modelo otimizado
best_rf_model = grid_search.best_estimator_
best_rf_pred = best_rf_model.predict(X_test)

best_rf_rmse = np.sqrt(mean_squared_error(y_test, best_rf_pred))
best_rf_r2 = r2_score(y_test, best_rf_pred)

print(f"Melhor Random Forest RMSE: {best_rf_rmse}")
print(f"Melhor Random Forest R¬≤: {best_rf_r2}")

"""* Regress√£o Linear e suas variantes (Ridge e Lasso) n√£o est√£o capturando bem as n√£o-linearidades e intera√ß√µes das vari√°veis.

* Random Forest foi muito superior, reduzindo o RMSE em mais de 1200 unidades, o que representa uma grande melhora na acur√°cia das previs√µes.

* O ajuste fino (Grid Search) melhorou ainda mais, mesmo com um n√∫mero reduzido de estimadores (n_estimators=50), o que tamb√©m impacta positivamente no tempo de processamento.
"""

import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Par√¢metros testados
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [10, 20],
    'min_samples_split': [2, 10]
}

rf = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_root_mean_squared_error')
grid_search.fit(X_train, y_train)

"""# Atribuir melhor modelo"""

best_rf_model = grid_search.best_estimator_

"""# Import√¢ncia das Features"""

import pandas as pd
import matplotlib.pyplot as plt

# Pega a import√¢ncia de cada vari√°vel
feature_importances = best_rf_model.feature_importances_
features = X.columns  # Certifique-se de estar usando o mesmo X do treino

# Organiza em um DataFrame
importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Plot
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'])
plt.xlabel('Import√¢ncia')
plt.ylabel('Vari√°veis')
plt.title('Import√¢ncia das Vari√°veis - Random Forest')
plt.gca().invert_yaxis()
plt.show()

"""# Avaliar o modelo com m√©tricas finais

"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Previs√µes com dados de teste
y_pred = best_rf_model.predict(X_test)

# M√©tricas
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"RMSE Final: {rmse}")
print(f"R¬≤ Final: {r2}")

import joblib
joblib.dump(best_rf_model, 'modelo_random_forest.pkl')

"""# Verificando variaveis de maiores impacvtos

"""

import pandas as pd
import matplotlib.pyplot as plt

# Pegando o melhor modelo encontrado pelo GridSearchCV
best_rf_model = grid_search.best_estimator_

# Extraindo a import√¢ncia das features
feature_importances = best_rf_model.feature_importances_
features = X_train.columns

# Criando um DataFrame para visualiza√ß√£o
importance_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Visualizando o top 10 (ou todos, se preferir)
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'][:10][::-1], importance_df['Importance'][:10][::-1], color='teal')
plt.xlabel('Import√¢ncia')
plt.ylabel('Vari√°vel')
plt.title('Top 10 Vari√°veis Mais Importantes')
plt.tight_layout()
plt.show()

# Se quiser ver o DataFrame completo
print(importance_df)

pip install shap

import shap

# Cria o explainer corretamente
explainer = shap.TreeExplainer(best_rf_model)

# Calcula os valores SHAP com check_additivity desativado
shap_values = explainer.shap_values(X_train, check_additivity=False)

# Exibe o gr√°fico de resumo
shap.summary_plot(shap_values, X_train)

"""* ‚ÄúAl√©m de treinar um modelo com bom desempenho (RMSE de ~4540 e R¬≤ de 0.87),
 utilizei a biblioteca SHAP para gerar interpretabilidade. Isso me permitiu identificar que o fator mais relevante para o custo de seguro sa√∫de foi o tabagismo, seguido da idade e do IMC. Isso √© importante pois ajuda o neg√≥cio a entender os fatores de risco e potencialmente atuar de forma preventiva.‚Äù

# üß† Insights do Projeto de Previs√£o de Custos M√©dicos

# üéØ Desempenho do Modelo
Algoritmo utilizado: RandomForestRegressor, otimizado com GridSearchCV.

M√©tricas finais de desempenho:

RMSE: 4540.28

R¬≤: 0.867

# Resultado indica que o modelo possui alta capacidade preditiva, explicando aproximadamente 87% da vari√¢ncia dos custos m√©dicos.

# üîç Import√¢ncia Global das Vari√°veis (Feature Importance)
As tr√™s vari√°veis com maior influ√™ncia no modelo s√£o:

* smoker (fumante)

* bmi (√≠ndice de massa corporal)

* age (idade)

* ‚û§ smoker
Fumar √© disparadamente o fator mais relevante no aumento dos custos m√©dicos.

# SHAP
Traz a a informa;√°o que os pacientes fumantes (em rosa) possuem alto impacto positivo na previs√£o de custo, validando o conhecimento m√©dico pr√©vio sobre doen√ßas relacionadas ao tabagismo.

‚û§ bmi
Altos valores de IMC est√£o associados a maiores custos.

# O modelo mostra que sobrepeso/obesidade est√° positivamente correlacionado com despesas m√©dicas.

‚û§ age
A idade tem impacto progressivo nos custos: quanto mais velho o paciente, maior o custo previsto.

Este comportamento √© intuitivo e esperado, refletindo aumento da demanda por servi√ßos de sa√∫de com o envelhecimento.

‚û§ children, region, sex
T√™m impacto menor, mas ainda contribuem.

A vari√°vel children sugere leve influ√™ncia, talvez relacionada √† composi√ß√£o familiar do plano.

region e sex aparecem com impacto quase nulo no modelo final.

# üó£Ô∏è Aplicando o SHAP Values
Utiliza√ß√£o da biblioteca shap para gerar interpretabilidade:

summary_plot permitiu visualiza√ß√£o da dire√ß√£o e intensidade dos impactos.

Refor√ßa transpar√™ncia e confian√ßa no modelo.

Interpreta√ß√£o dos SHAP values demonstra que o modelo n√£o apenas √© acurado, mas tamb√©m explic√°vel, facilitando a tomada de decis√£o em contextos reais.

# üìà Potenciais aplica√ß√µes no neg√≥cio
Direcionamento de pol√≠ticas preventivas para fumantes e pacientes com alto IMC.

Prioriza√ß√£o de grupos de risco em campanhas de sa√∫de.

Precifica√ß√£o mais justa de planos de sa√∫de conforme o perfil do paciente.

*__________________________________________________________________________________________________*

# üß† Conclus√£o do Projeto

* ‚Äì Previs√£o de Custos M√©dicos com Random Forest e SHAP
Este projeto teve como objetivo prever os custos m√©dicos de pacientes com base em caracter√≠sticas demogr√°ficas e de sa√∫de, utilizando um modelo de Random Forest Regressor. A seguir, os principais resultados e aprendizados obtidos:

* ‚úÖ Performance do Modelo
RMSE final: 4.540,27
Um erro m√©dio relativamente baixo, mostrando que o modelo consegue fazer boas previs√µes de custos com base nos dados fornecidos.

* R¬≤ final: 0.867
O modelo explica aproximadamente 87% da variabilidade dos custos m√©dicos, o que √© um excelente resultado para problemas de regress√£o em sa√∫de.

* üß¨ Import√¢ncia das Vari√°veis
A an√°lise de import√¢ncia revelou que as principais vari√°veis que influenciam os custos m√©dicos s√£o:

* smoker (fumante)

* bmi (√≠ndice de massa corporal)

* age (idade)

* Essas vari√°veis possuem alta correla√ß√£o com o custo dos planos de sa√∫de e tratamentos, sendo smoker a mais influente, com mais de 64% da import√¢ncia relativa.

# üìä SHAP Values
A utiliza√ß√£o de SHAP permitiu visualizar o impacto de cada vari√°vel individual sobre as previs√µes:

* Fumantes com alto SHAP Value tendem a ter custos significativamente maiores.

* Altos valores de BMI e idade tamb√©m influenciam positivamente os custos, como esperado em contexto de sa√∫de.

* O gr√°fico SHAP tamb√©m ajudou a confirmar o bom comportamento do modelo, com interpreta√ß√µes alinhadas √† l√≥gica m√©dica.

*_________________________________________________________
*

# üíº Recomenda√ß√µes ao Neg√≥cio
Com base nas analises segue recomenda√ß√µes relevantes para o setor de seguros de sa√∫de ou gest√£o de benef√≠cios corporativos:

# 1. Pol√≠ticas Preventivas para Fumantes
Como a vari√°vel "smoker" foi a mais impactante nos custos, sugerimos implementar programas de cessa√ß√£o do tabagismo.

* Incentivar pr√°ticas como apoio psicol√≥gico, terapias e benef√≠cios por abandono do cigarro pode reduzir drasticamente os custos m√©dicos no m√©dio/longo prazo.

# 2. Monitoramento e Incentivo √† Sa√∫de Preventiva
Vari√°veis como "bmi" (√≠ndice de massa corporal) e "age" tamb√©m s√£o altamente relevantes.

* Recomenda-se adotar campanhas de controle de peso, alimenta√ß√£o saud√°vel e exerc√≠cios f√≠sicos para reduzir sinistros relacionados a obesidade e sedentarismo.

Para p√∫blicos mais experiente, ampliar exames peri√≥dicos e a√ß√µes de preven√ß√£o espec√≠ficas por faixa et√°ria.

# 3. Modelagem de Risco para Precifica√ß√£o Personalizada

O modelo Random Forest pode ser integrado aos sistemas internos para ajudar na precifica√ß√£o inteligente de planos de sa√∫de, com base em perfis de risco.

Clientes com maior propens√£o a gerar altos custos podem ser identificados e acompanhados com a√ß√µes preventivas personalizadas.

# 4. Aloca√ß√£o mais Eficiente de Recursos

Com a previs√£o mais acurada dos custos, √© poss√≠vel planejar melhor o or√ßamento, otimizando:

Gest√£o de sinistros

Negocia√ß√£o com hospitais

Pacotes personalizados por perfil de cliente

# 5. Uso de Modelos Interpretable-by-Design
O uso de SHAP values garante interpretabilidade ‚Äî essencial no setor da sa√∫de.

Isso fortalece a conformidade regulat√≥ria (compliance) e permite tomadas de decis√£o mais embasadas por stakeholders n√£o t√©cnicos.
"""

